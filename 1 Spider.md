SEO 搜索引擎优化
SEM 搜索引擎营销

##### 搜索引擎原理
大概会涉及 Spider、内容处理、分词、去重、索引、内容相关性、链接分析、判断页面用户体验、反作弊、人工干预、缓存机制、用户需求分析等
* 主动抓去网页进行一系列处理后建立索引，等待用户搜索
    * 派出 Spider，按照一定策略把网页抓回到搜索引擎服务器；
    * 对抓回的网页进行链接抽离、内容处理，消除噪声、提取该页主题文本内容等；
    * 对网页的文本内容进行中文分词、去除停止词等；
    * 对网页内容进行分词后判断该页面内容与已索引网页是否有重复，剔除重复页，对剩余网页进行倒排索引，然后等待用户的检索。
* 分析用户搜索意图，展现用户所需要的搜索结果
    * 先对用户所查询的关键词进行分词处理，并根据用户的地理位置和历史检索特征进行用户需求分析，以便使用地域性搜索结果和个性化搜索结果展示用户最重要的内容；
    * 查询缓存中是否有该关键词的查询结果，如果有，为了更快地呈现查询结果，搜索引擎会根据当下用户的各种信息判断其真正需求，对缓存中的结果**进行微调**或直接呈现给用户；
    * 如果用户所查询的关键词在缓存中不存在，那么就在索引库中的网页进行调取排名呈现，并将该关键词和对应的搜索结果加入到缓存中；
    * 网页排名是根据用户的搜索词和搜索需求，对索引库中的网页进行**相关性、重要性（链接权重分析）和用户体验的高低进行分析所得出的**。用户在搜索结果中的点击和重复搜索行为，也可以告诉搜索引擎，用户对搜索结果页的使用体验。


##### Spider
* 批量型，一般有明显的抓取范围和目标，如数据采集工具   
* 增量型，没有固定目标、范围和时间限制，一般会无休止地抓下去，如百度、Google
* 垂直型，只对特定主题、特定内容或特定行业的网页惊醒抓取


##### Spider抓取策略
在抓到一个新页面时，提取该页面上的链接，并把提取到的链接和已抓取 URL 列表中的链接进行逐一对比，如果发现该链接已经抓取过了，就会直接丢弃，如果发现该链接还未抓取，就会把该链接放到待抓取 URL 队列末尾等待抓取。
Spider 眼中的互联网网页可以分为以下四类：
* 已经抓取过的网页；
* 待抓取的网页；
* 可抓取的网页；
    * 当下可能还不知道这些页面的存在，最终会发现这些页面的存在
* 暗网中的网页；
    * 可能这些页面中有链接指向以上三类网页，但是通过以上三类网页并不能找到这些页面，如网站内需要手动提交查询才能获得的网页

##### Spider抓取方式
* 深度优先策略
* 广度优先策略

##### 实际抓取方式
可以看出依靠外部链接来引导 Spider 和提升网站权重，以及依靠内容长期运营网站权重的重用性
* 重要页面优先抓取策略
    * 排序的依据是：页面获得的已抓取页面链接的多少和链接权重的高低
* 大站优先策略

Spider抓取一个网页后会优先把网页中的URL提取出来，同时记录和计算**URL的形式、位置、锚文本、当前页所赋予的权值信息**，然后把这些URL合并到抓取队列中，并根据每个URL所附有的总权值等信息进行抓取队列的排序。Spider 就是根据这个**不断变化顺序的URL队列**来抓取网页内容的，而并不是从一个页面沿着链接爬到另一个页面抓取。

Spider 一般会根据以下四个方面来确定对已索引网页的再次抓取频率
* 用户体验
    * 本着**优先更新大部分用户所需要内容的原则**，所有用户提交查询结果的前几页，都是值的索引及时更新的。
    * 所以一般搜索引擎会搜集所有用户的搜索请求，然后统计所有搜索结果中用户可能看到的网页，继而进行优先再次抓取和更新
    * 理论上，这些网页被搜索到的次数越多，再次被抓取的概率就会越高
* 历史更新频率
    * 如果某个网页持续没有变化，可能搜索引擎就会降低对其抓取的频率，甚至不再对其进行再次抓取
    * 理论上 Spider 发现一个新 URL 抓取并索引后，会很快进行二次抓取。如果没有发现内容变动，就会降低抓取频率，这样慢慢地发现网页的更新频率，以调整到最佳的抓取频率。
* 网页类型
    * 不同的网页类型有不同的更新频率。首页和目录页是 Spider 经常光顾的页面。
* 网页权重

##### 百度“阿拉丁”解决暗网抓取
对于有独特资源的网站来说绝对是个福利

##### Spider 和普通用户的区别
* Spider 可以分辨出网页中是否有隐藏内容，是否被挂了黑链等，但是不能完全了解网页中图片的内容，更不能读取JavaScript、Iframe、Ajax 和 Flash 中的内容，普通用户却是恰恰相反；
* Spider 没有 Referer， 对网站的抓取全部都是直接访问，而普通用户中除了直接访问的用户外一般都是有 Referer 的；
* Spider 对网站的访问没有 Cookie，但普通用户是有的；
* Spider 不会主动注册登入网站，但是普通用户是可以的；原则上 Spider 不会抓取和分析网站 robots 中已经屏蔽的内容，但是普通用户是可以正常访问的；
* Spider 对于有多个动态参数网站的抓取，可能会陷入死循环，但是普通用户是不会的；
* Spider 对于列表中前几页的新内容抓取可能不好，但是感兴趣的普通用户会依次浏览；
* Spider **暂时还不能真正判断文章是不是原创的**，但是普通用户可以通过多种方式来确定文章是原创还是采集转载等。

